import os
import time
from datetime import datetime
from typing import List, Dict, Optional
from src.config import Config
from src.secret_detector import SecretDetector
from src.github_scanner import GitHubScanner
from src.report_generator import ReportGenerator
from src.scan_history import ScanHistory

class CloudScanner:
    """Scanner principal"""
    
    def __init__(self, github_token: str = None, skip_scanned: bool = True):
        self.config = Config()
        self.github_token = github_token or self.config.GITHUB_TOKEN
        self.skip_scanned = skip_scanned
        
        # Initialisation des composants
        self.secret_detector = SecretDetector()
        self.github_scanner = GitHubScanner(self.github_token)
        self.report_generator = ReportGenerator()
        self.scan_history = ScanHistory()
        
        # Suivi du temps
        self.scan_start_time = time.time()
        self.timeout_minutes = self.config.TIMEOUT_MINUTES
    
    def scan_ai_projects(self, max_repos: int = 50) -> str:
        """Scan automatique des projets AI"""
        print("ğŸš€ DÃ©marrage du scan automatique des projets AI")
        scan_start_time = datetime.now()
        
        # DÃ©finition du filtre de dÃ©pÃ´ts dÃ©jÃ  scannÃ©s
        def is_scanned(repo_full_name: str) -> bool:
            return self.scan_history.is_scanned(repo_full_name) if self.skip_scanned else False
        
        # Recherche des dÃ©pÃ´ts AI
        repos_to_scan = self.github_scanner.search_ai_repos(
            max_repos=max_repos,
            skip_filter=is_scanned if self.skip_scanned else None
        )
        
        if not repos_to_scan:
            print("âŒ Aucun dÃ©pÃ´t AI trouvÃ© Ã  scanner")
            return ""
        
        # Scan de tous les dÃ©pÃ´ts
        all_findings = []
        for idx, repo in enumerate(repos_to_scan, 1):
            # VÃ©rification du timeout
            if self._check_timeout(idx, len(repos_to_scan)):
                break
            
            print(f"ğŸ” [{idx}/{len(repos_to_scan)}] Scanning du dÃ©pÃ´t: {repo['full_name']}")
            
            try:
                findings = self._scan_repository(repo, scan_type="auto:ai-projects")
                all_findings.extend(findings)
                
                # Marque comme scannÃ©
                self.scan_history.mark_as_scanned(
                    repo['full_name'],
                    len(findings),
                    "auto:ai-projects"
                )
                
                # Petite pause pour Ã©viter le rate limiting
                time.sleep(0.5)
                
            except Exception as e:
                print(f"âš ï¸ Erreur lors du scan de {repo['full_name']}: {e}")
                continue
        
        # GÃ©nÃ©ration du rapport
        report_path = self.report_generator.generate_report(
            all_findings, scan_start_time, scan_type="auto:ai-projects"
        )
        
        # Nettoyage de l'historique
        self.scan_history.clear_old_entries()
        
        return report_path
    
    def scan_user_repos(self, username: str, max_repos: int = 30) -> str:
        """Scan les dÃ©pÃ´ts d'un utilisateur spÃ©cifique"""
        print(f"ğŸ‘¤ Scanning des dÃ©pÃ´ts de l'utilisateur: {username}")
        scan_start_time = datetime.now()
        
        # RÃ©cupÃ©ration des dÃ©pÃ´ts de l'utilisateur
        repos = self._get_user_repos(username, max_repos)
        
        all_findings = []
        for idx, repo in enumerate(repos, 1):
            if self._check_timeout(idx, len(repos)):
                break
            
            print(f"ğŸ” [{idx}/{len(repos)}] Scanning: {repo['full_name']}")
            
            findings = self._scan_repository(repo, scan_type=f"user:{username}")
            all_findings.extend(findings)
            
            self.scan_history.mark_as_scanned(
                repo['full_name'],
                len(findings),
                f"user:{username}"
            )
            
            time.sleep(0.5)
        
        report_path = self.report_generator.generate_report(
            all_findings, scan_start_time, scan_type=f"user:{username}"
        )
        
        return report_path
    
    def scan_organization(self, org_name: str, max_repos: int = 50) -> str:
        """Scan les dÃ©pÃ´ts d'une organisation"""
        print(f"ğŸ¢ Scanning de l'organisation: {org_name}")
        scan_start_time = datetime.now()
        
        repos = self._get_org_repos(org_name, max_repos)
        
        all_findings = []
        for idx, repo in enumerate(repos, 1):
            if self._check_timeout(idx, len(repos)):
                break
            
            print(f"ğŸ” [{idx}/{len(repos)}] Scanning: {repo['full_name']}")
            
            findings = self._scan_repository(repo, scan_type=f"org:{org_name}")
            all_findings.extend(findings)
            
            self.scan_history.mark_as_scanned(
                repo['full_name'],
                len(findings),
                f"org:{org_name}"
            )
            
            time.sleep(0.5)
        
        report_path = self.report_generator.generate_report(
            all_findings, scan_start_time, scan_type=f"org:{org_name}"
        )
        
        return report_path
    
    def scan_single_repo(self, repo_full_name: str) -> str:
        """Scan un dÃ©pÃ´t unique"""
        print(f"ğŸ“¦ Scanning du dÃ©pÃ´t unique: {repo_full_name}")
        scan_start_time = datetime.now()
        
        owner, repo_name = repo_full_name.split('/')
        repo_data = {
            'full_name': repo_full_name,
            'owner': {'login': owner},
            'name': repo_name
        }
        
        findings = self._scan_repository(repo_data, scan_type="single")
        
        report_path = self.report_generator.generate_report(
            findings, scan_start_time, scan_type=f"repo:{repo_full_name}"
        )
        
        return report_path
    
    def _scan_repository(self, repo: Dict, scan_type: str = "manual") -> List[Dict]:
        """Scan un dÃ©pÃ´t GitHub"""
        owner = repo['owner']['login']
        repo_name = repo['name']
        repo_full_name = repo['full_name']
        
        print(f"   ğŸ“ Analyse de la structure du dÃ©pÃ´t...")
        
        # RÃ©cupÃ©ration de tous les fichiers
        files_to_scan = self._get_all_files(owner, repo_name)
        
        findings = []
        scanned_files = 0
        
        for file_path in files_to_scan:
            # VÃ©rifie si c'est un fichier Ã  scanner
            if not self._should_scan_file(file_path):
                continue
            
            try:
                # RÃ©cupÃ¨re le contenu du fichier
                content = self.github_scanner.get_file_content(owner, repo_name, file_path)
                if content:
                    # DÃ©tecte les secrets
                    file_findings = self.secret_detector.detect_secrets_in_text(content, file_path)
                    
                    for finding in file_findings:
                        finding.update({
                            'repo_url': f"https://github.com/{repo_full_name}",
                            'repo_name': repo_full_name,
                            'scan_type': scan_type
                        })
                        findings.append(finding)
                    
                    scanned_files += 1
                    
            except Exception as e:
                print(f"   âš ï¸ Erreur avec le fichier {file_path}: {e}")
                continue
        
        print(f"   âœ… ScannÃ© {scanned_files} fichiers, trouvÃ© {len(findings)} problÃ¨mes")
        return findings
    
    def _get_all_files(self, owner: str, repo_name: str, path: str = "") -> List[str]:
        """RÃ©cupÃ¨re rÃ©cursivement tous les fichiers d'un dÃ©pÃ´t"""
        all_files = []
        
        try:
            contents = self.github_scanner.get_repo_contents(owner, repo_name, path)
            
            for item in contents:
                if item['type'] == 'file':
                    all_files.append(item['path'])
                elif item['type'] == 'dir':
                    dir_name = item['name']
                    
                    # VÃ©rifie si c'est un rÃ©pertoire Ã  exclure
                    if dir_name in self.config.EXCLUDE_DIRS or \
                       any(dir_name.startswith(exclude) for exclude in self.config.EXCLUDE_DIRS):
                        continue
                    
                    # Scan rÃ©cursif
                    sub_files = self._get_all_files(owner, repo_name, item['path'])
                    all_files.extend(sub_files)
        
        except Exception as e:
            print(f"   âš ï¸ Erreur lors de la rÃ©cupÃ©ration des fichiers: {e}")
        
        return all_files
    
    def _should_scan_file(self, file_path: str) -> bool:
        """DÃ©termine si un fichier doit Ãªtre scannÃ©"""
        # VÃ©rifie l'extension
        has_valid_extension = any(file_path.endswith(ext) for ext in self.config.SCAN_EXTENSIONS)
        if not has_valid_extension:
            return False
        
        # VÃ©rifie les rÃ©pertoires exclus
        for exclude_dir in self.config.EXCLUDE_DIRS:
            if f"/{exclude_dir}/" in file_path or file_path.startswith(f"{exclude_dir}/"):
                return False
        
        # VÃ©rifie les fichiers exclus
        for exclude_pattern in self.config.EXCLUDE_FILES:
            if exclude_pattern.startswith('*'):
                if file_path.endswith(exclude_pattern[1:]):
                    return False
            elif exclude_pattern in file_path:
                return False
        
        return True
    
    def _get_user_repos(self, username: str, max_repos: int) -> List[Dict]:
        """RÃ©cupÃ¨re les dÃ©pÃ´ts d'un utilisateur"""
        url = f"{self.config.GITHUB_API_URL}/users/{username}/repos"
        params = {
            'type': 'all',
            'sort': 'updated',
            'per_page': min(max_repos, 100)
        }
        
        response = requests.get(url, headers=self.github_scanner.headers, params=params)
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ Erreur lors de la rÃ©cupÃ©ration des dÃ©pÃ´ts de {username}: {response.status_code}")
            return []
    
    def _get_org_repos(self, org_name: str, max_repos: int) -> List[Dict]:
        """RÃ©cupÃ¨re les dÃ©pÃ´ts d'une organisation"""
        url = f"{self.config.GITHUB_API_URL}/orgs/{org_name}/repos"
        params = {
            'type': 'all',
            'sort': 'updated',
            'per_page': min(max_repos, 100)
        }
        
        response = requests.get(url, headers=self.github_scanner.headers, params=params)
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ Erreur lors de la rÃ©cupÃ©ration des dÃ©pÃ´ts de {org_name}: {response.status_code}")
            return []
    
    def _check_timeout(self, current_idx: int, total_repos: int) -> bool:
        """VÃ©rifie si le timeout est atteint"""
        elapsed_minutes = (time.time() - self.scan_start_time) / 60
        
        if elapsed_minutes >= self.timeout_minutes:
            print(f"â° Timeout atteint ({elapsed_minutes:.1f} minutes)")
            print(f"ğŸ“Š Progression: {current_idx}/{total_repos} dÃ©pÃ´ts scannÃ©s")
            print("ğŸ’¾ Les donnÃ©es sont sauvegardÃ©es, reprise au prochain scan")
            return True
        
        return False